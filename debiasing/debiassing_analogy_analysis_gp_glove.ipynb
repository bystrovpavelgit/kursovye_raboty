{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"J2WiDLsS_m3v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651250182780,"user_tz":0,"elapsed":29501,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}},"outputId":"d6a8a820-2260-497a-b348-2617caf567d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'debiasing_evaluation'...\n","remote: Enumerating objects: 13, done.\u001b[K\n","remote: Counting objects: 100% (13/13), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 13 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (13/13), done.\n","Cloning into 'gp_debias'...\n","remote: Enumerating objects: 66, done.\u001b[K\n","remote: Total 66 (delta 0), reused 0 (delta 0), pack-reused 66\u001b[K\n","Unpacking objects: 100% (66/66), done.\n","Cloning into 'gn_glove'...\n","remote: Enumerating objects: 199, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 199 (delta 2), reused 6 (delta 2), pack-reused 193\u001b[K\n","Receiving objects: 100% (199/199), 67.78 KiB | 4.84 MiB/s, done.\n","Resolving deltas: 100% (88/88), done.\n","d\t     eval_word_embeddings.py  LICENSE\t run.sh   src\n","download.sh  hyperparams\t      README.md  SemBias  wordlist\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1jrbQmpB5ZNH4w54yujeAvNFAfVEG0SuE\n","To: /content/GloVe.zip\n","100% 368M/368M [00:02<00:00, 142MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1v82WF43w-lE-vpZd0JC1K8WYZQkTy_ii\n","To: /content/GN-GloVe-L1-0.8-0.8.txt.zip\n","100% 369M/369M [00:04<00:00, 85.1MB/s]\n","Archive:  GloVe.zip\n","  inflating: vectors.txt             \n","glove.txt\n"]}],"source":["################################################################\n","## GPU Should be enabled in colab\n","## This notebook is reproducing results from https://github.com/kanekomasahiro/gp_debias\n","## You should upload debiasing.ipynb into https://colab.research.google.com/ to run it\n","################################################################\n","!git clone https://github.com/pavelbystrov1/debiasing_evaluation\n","!git clone https://github.com/kanekomasahiro/gp_debias\n","!cd ./gp_debias; mkdir d; cd d; git clone https://github.com/uclanlp/gn_glove.git\n","!paste ./gp_debias/d/gn_glove/wordlist/female_word_file.txt ./gp_debias/d/gn_glove/wordlist/male_word_file.txt > ./gp_debias/wordlist/gender_pair.tsv \n","!cp -r ./gp_debias/d/gn_glove/SemBias ./gp_debias/\n","!ls ./gp_debias\n","##############################################################################\n","# Glove embedding trained on wikidump dataset can be downloaded using code below or manually - https://drive.google.com/open?id=1jrbQmpB5ZNH4w54yujeAvNFAfVEG0SuE\n","# GN-Glove embedding trained on wikidump dataset can be downloaded using code below or manually - https://drive.google.com/file/d/1v82WF43w-lE-vpZd0JC1K8WYZQkTy_ii/\n","##############################################################################\n","!gdown --id '1jrbQmpB5ZNH4w54yujeAvNFAfVEG0SuE'\n","!gdown --id '1v82WF43w-lE-vpZd0JC1K8WYZQkTy_ii'\n","##########################################\n","# unzip GloVe embedding\n","##########################################\n","!cd gp_debias; mkdir -p src/glove_model\n","!cp GloVe.zip ./gp_debias/src/glove_model/\n","!cd gp_debias/src/glove_model; unzip GloVe.zip\n","!cd gp_debias/src/glove_model; sed -i \"1s/^/322636 300\\n/\" vectors.txt\n","!cd gp_debias/; mkdir embeddings\n","!mv gp_debias/src/glove_model/vectors.txt gp_debias/embeddings/glove.txt\n","!cd gp_debias; mkdir -p src/debiased_glove\n","!ls gp_debias/embeddings/"]},{"cell_type":"code","source":["###########################################\n","# create classifiers for glove\n","# save gp_glove embedding\n","###########################################\n","!cd gp_debias; python src/train.py glove\n","!cd gp_debias; python src/eval.py glove\n","!ls gp_debias/src/debiased_glove\n","#############################################################\n","# create folder for evaluation of generated word embeddings\n","# and copy glove.txt and gp_glove.txt there\n","#############################################################\n","!cd ./debiasing_evaluation; mkdir glove\n","!mv gp_debias/embeddings/glove.txt debiasing_evaluation/glove/glove.txt\n","!mv gp_debias/src/debiased_glove/gender_debiased.txt debiasing_evaluation/glove/gp_glove.txt\n","!mv gp_debias/src/debiased_glove/gender_debiased.bin debiasing_evaluation/glove/gp_glove.bin\n","#######################################\n","#      prepare data for GN-Glove\n","#######################################\n","!cd gp_debias; \n","!cp /content/GN-GloVe-L1-0.8-0.8.txt.zip /content/gp_debias/src/glove_model/\n","!cd gp_debias/src/glove_model; unzip \"GN-GloVe-L1-0.8-0.8.txt.zip\"\n","!cd gp_debias/src/glove_model; sed -i \"1s/^/322636 300\\n/\" vectors300.txt\n","!cp gp_debias/src/glove_model/vectors300.txt gp_debias/src/glove_model/glove.txt\n","!mv gp_debias/src/glove_model/glove.txt gp_debias/embeddings/glove.txt\n","!ls gp_debias/src/glove_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BAUutgi_O2k","executionInfo":{"status":"ok","timestamp":1651250843696,"user_tz":0,"elapsed":660925,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}},"outputId":"0213abd6-8c3d-4f62-8478-1220edeff43d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading word embedding\n","Loading data\n","Pre-training autoencoder\n","/content/gp_debias/src/pre_train_autoencoder.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  eval_inputs = torch.split(torch.FloatTensor(emb_list[:hp.pta_dev_num]), hp.pta_batch_size)\n","src/train.py:426: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n","  train_female_embs = [encoder(torch.FloatTensor(emb[word[0]]).cuda()).data if hp.gpu >= 0 else encoder(torch.FloatTensor(emb[word[0]])).data for word in train_words['female & male']]\n","Pre-training classifier\n","Building female & male classifiers\n","Setting optimizer\n","Start training\n","Generating emb...\n","Start generating\n","src/eval.py:95: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n","  inputs = torch.split(torch.stack([torch.FloatTensor(w2v[word]) for word in w2v.vocab.keys()]), 1024)\n","SemBias\n","definition: 0.8386363636363636\n","stereotype: 0.08181818181818182\n","none: 0.07954545454545454\n","sub definition: 0.625\n","sub stereotype: 0.15\n","sub none: 0.225\n","Saving emb...\n","gender_debiased.bin  gender_debiased.txt\n","Archive:  GN-GloVe-L1-0.8-0.8.txt.zip\n","  inflating: vectors300.txt          \n","   creating: __MACOSX/\n","  inflating: __MACOSX/._vectors300.txt  \n","best_model.pt  GloVe.zip  GN-GloVe-L1-0.8-0.8.txt.zip  __MACOSX  vectors300.txt\n"]}]},{"cell_type":"code","source":["###########################################\n","# create classifiers for GN-glove and save gp_gn_glove embedding\n","###########################################\n","!cd gp_debias; python src/train.py glove\n","!cd gp_debias; python src/eval.py glove\n","!ls gp_debias/src/debiased_glove\n","#############################################################\n","# copy GN-glove and gp_gn_glove there\n","#############################################################\n","!mv gp_debias/embeddings/glove.txt debiasing_evaluation/glove/gn_glove.txt\n","!mv gp_debias/src/debiased_glove/gender_debiased.txt debiasing_evaluation/glove/gp_gn_glove.txt\n","!mv gp_debias/src/debiased_glove/gender_debiased.bin debiasing_evaluation/glove/gp_gn_glove.bin\n","!ls debiasing_evaluation/glove/\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBOyS9QW_O7y","executionInfo":{"status":"ok","timestamp":1651251470091,"user_tz":0,"elapsed":276382,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}},"outputId":"7920e365-ad31-481f-ee78-e46b981fb1df"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading word embedding\n","Loading data\n","Pre-training autoencoder\n","/content/gp_debias/src/pre_train_autoencoder.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  eval_inputs = torch.split(torch.FloatTensor(emb_list[:hp.pta_dev_num]), hp.pta_batch_size)\n","src/train.py:426: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n","  train_female_embs = [encoder(torch.FloatTensor(emb[word[0]]).cuda()).data if hp.gpu >= 0 else encoder(torch.FloatTensor(emb[word[0]])).data for word in train_words['female & male']]\n","Pre-training classifier\n","Building female & male classifiers\n","Setting optimizer\n","Start training\n","Generating emb...\n","Start generating\n","src/eval.py:95: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n","  inputs = torch.split(torch.stack([torch.FloatTensor(w2v[word]) for word in w2v.vocab.keys()]), 1024)\n","SemBias\n","definition: 0.9795454545454545\n","stereotype: 0.011363636363636364\n","none: 0.00909090909090909\n","sub definition: 0.8\n","sub stereotype: 0.125\n","sub none: 0.075\n","Saving emb...\n","gender_debiased.bin  gender_debiased.txt\n","glove.txt     gp_glove.bin  gp_gn_glove.bin\n","gn_glove.txt  gp_glove.txt  gp_gn_glove.txt\n"]}]},{"cell_type":"code","source":["###############################################################\n","# Load SimLex, datasets from Semantic-measure-assessment study and Google anthologies\n","# Copy wordlists, SemBias and other test datasets to do evaluation later\n","###############################################################\n","!wget https://fh295.github.io/SimLex-999.zip\n","!git clone https://github.com/MohamedAliHadjTaieb/Semantic-measure-assessment-review-study\n","!wget http://download.tensorflow.org/data/questions-words.txt\n","!unzip SimLex-999.zip\n","!mv questions-words.txt debiasing_evaluation/glove/google_anthology_ds.txt\n","!mv SimLex-999/SimLex-999.txt debiasing_evaluation/glove/SimLex-999.txt\n","!cp \"Semantic-measure-assessment-review-study/DataSets/English/Semantic Relatedness/MT771.csv\" debiasing_evaluation/glove/MTurk.csv\n","!cp \"Semantic-measure-assessment-review-study/DataSets/English/Semantic Relatedness/RW2034.csv\" debiasing_evaluation/glove/\n","!cp \"Semantic-measure-assessment-review-study/DataSets/English/Semantic Relatedness/WordSim353.csv\" debiasing_evaluation/glove/\n","!cp \"Semantic-measure-assessment-review-study/DataSets/English/Semantic Similarity/RG65.csv\" debiasing_evaluation/glove/\n","!cp \"Semantic-measure-assessment-review-study/DataSets/English/Semantic Similarity/MEN3000.csv\" debiasing_evaluation/glove/\n","!cp -r ./gp_debias/d/gn_glove/SemBias debiasing_evaluation/glove/\n","!cp -r ./gp_debias/wordlist debiasing_evaluation/glove/\n","############################################\n","#            Preparation DONE\n","############################################"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXT3P27w_O_8","executionInfo":{"status":"ok","timestamp":1651251477827,"user_tz":0,"elapsed":3798,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}},"outputId":"8459bfb7-f140-4f16-c87d-3176471552ee"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-29 16:57:53--  https://fh295.github.io/SimLex-999.zip\n","Resolving fh295.github.io (fh295.github.io)... 185.199.111.153, 185.199.109.153, 185.199.108.153, ...\n","Connecting to fh295.github.io (fh295.github.io)|185.199.111.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16805 (16K) [application/zip]\n","Saving to: ‘SimLex-999.zip’\n","\n","SimLex-999.zip      100%[===================>]  16.41K  --.-KB/s    in 0s      \n","\n","2022-04-29 16:57:54 (32.7 MB/s) - ‘SimLex-999.zip’ saved [16805/16805]\n","\n","Cloning into 'Semantic-measure-assessment-review-study'...\n","remote: Enumerating objects: 1365, done.\u001b[K\n","remote: Total 1365 (delta 0), reused 0 (delta 0), pack-reused 1365\u001b[K\n","Receiving objects: 100% (1365/1365), 690.99 KiB | 2.42 MiB/s, done.\n","Resolving deltas: 100% (618/618), done.\n","--2022-04-29 16:57:55--  http://download.tensorflow.org/data/questions-words.txt\n","Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.76.128, 2a00:1450:400c:c00::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.76.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 603955 (590K) [text/plain]\n","Saving to: ‘questions-words.txt’\n","\n","questions-words.txt 100%[===================>] 589.80K  --.-KB/s    in 0.002s  \n","\n","2022-04-29 16:57:55 (239 MB/s) - ‘questions-words.txt’ saved [603955/603955]\n","\n","Archive:  SimLex-999.zip\n","   creating: SimLex-999/\n","  inflating: SimLex-999/README.txt   \n","  inflating: SimLex-999/SimLex-999.txt  \n"]}]},{"cell_type":"code","source":["##############################################\n","# for Google colab path starts with /content/ if you will run this ipynb-file localy please remove \"/content\" from directories below\n","##############################################\n","import matplotlib\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","\n","\n","from numpy import dot\n","from numpy.linalg import norm\n","from gensim.models import KeyedVectors\n","import pathlib\n","from pathlib import Path\n","\n","import numpy as np\n","from scipy import stats\n","from functools import reduce\n","import pandas as pd\n","import seaborn as sns\n","\n","SEM_BIAS = '/content/debiasing_evaluation/glove/SemBias/SemBias'\n","GP_GN = '/content/debiasing_evaluation/glove/gp_gn_glove.txt'\n","GN_GLOVE = '/content/debiasing_evaluation/glove/gn_glove.txt'\n","GLOVE = '/content/debiasing_evaluation/glove/glove.txt'\n","GOOGLE_ANT = '/content/debiasing_evaluation/glove/google_anthology_ds.txt'\n","RG65 = '/content/debiasing_evaluation/glove/RG65.csv'\n","WS = '/content/debiasing_evaluation/glove/WordSim353.csv'\n","MTURK = '/content/debiasing_evaluation/glove/MTurk.csv'\n","RW = '/content/debiasing_evaluation/glove/RW2034.csv'\n","MEN = '/content/debiasing_evaluation/glove/MEN3000.csv'\n","SIMLEX = '/content/debiasing_evaluation/glove/SimLex-999.txt'\n","SEM_EVAL = '/content/debiasing_evaluation/glove/SemEval'\n","GP_GLOVE = '/content/debiasing_evaluation/glove/gp_glove.txt'\n","STEREOTYPE = '/content/debiasing_evaluation/glove/wordlist/stereotype_list.tsv'\n","NOGENDER = '/content/debiasing_evaluation/glove/wordlist/no_gender_list.tsv'\n","GENDER = '/content/debiasing_evaluation/glove/wordlist/gender_pair.tsv'\n"],"metadata":{"id":"bTJ7gBst_PDn","executionInfo":{"status":"ok","timestamp":1651251485302,"user_tz":0,"elapsed":1439,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"WAJKOy9H6293","executionInfo":{"status":"ok","timestamp":1651251573153,"user_tz":0,"elapsed":84054,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}}},"outputs":[],"source":["emb_gn = KeyedVectors.load_word2vec_format(GP_GLOVE, binary=False)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"h5yMzk8YtCI5","executionInfo":{"status":"ok","timestamp":1651251583769,"user_tz":0,"elapsed":10628,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}}},"outputs":[],"source":["def get_vocabulary(fn = GLOVE):\n","    with open(fn, \"r\") as f:\n","        vocab = [line.lower().split()[0] for line in f]\n","    return vocab[1:]\n","\n","\n","def get_analogy_ds(fn = GOOGLE_ANT):\n","    with open(fn, \"r\") as f:\n","        vocab = [line.lower().split() for line in f if line[0] != ':']\n","    return vocab\n","\n","\n","def get_semeval(path = SEM_EVAL):\n","    fnames = Path(path).rglob(\"*.txt\")\n","    full_lst = []\n","    for n in fnames:\n","        pth = str(n)\n","        with open(pth, \"r\") as f:\n","            vocab = [line.replace('\"', \"\").lower().split() for line in f if line[0] != '#']\n","        full_lst = full_lst + vocab\n","    res = [[p[0].split(':')] + [p[1].split(':')]+[p[2].split(':')] + [p[3].split(':')] for p in full_lst]\n","    return res\n","\n","def cosine_sim(v, w):\n","    \"\"\"cosine similarity\"\"\"\n","    return np.dot(w, v)/((np.linalg.norm(w)) * (np.linalg.norm(v) + 0.000001))\n","\n","\n","def find_simi(lst, a, b, c, vocab, emb):\n","    \"\"\"find argmax using 3COSADD method\"\"\"\n","    v1 = b - a + c\n","    amax = 0.\n","    result = \"\"\n","    for w2 in vocab:\n","        if w2 not in lst:\n","            sim = cosine_sim(emb[w2], v1)\n","            if sim > amax:\n","                result = w2\n","                amax = sim\n","    return result, amax\n","\n","\n","def cosine_sim(v, w, eps = 0.001):\n","    \"\"\"cosine similarity\"\"\"\n","    return np.dot(w, v)/((np.linalg.norm(w)+0.000001) * (np.linalg.norm(v)+eps))\n","\n","\n","def find_simi(lst, a, b, c, vocab, emb):\n","    \"\"\"find argmax using 3COSADD method\"\"\"\n","    v1 = b - a + c\n","    amax = 0.\n","    result = \"\"\n","    for w2 in vocab:\n","        if w2 not in lst:\n","            sim = cosine_sim(emb[w2], v1)\n","            if sim > amax:\n","                result = w2\n","                amax = sim\n","    return result, amax\n","\n","\n","def calculate_acc_for_analogies(anthologies, emb_gn, vocab_gn):\n","    \"\"\" check overall accuracy of anthologies \"\"\"\n","    corrects = 0\n","    total = 0\n","    a, b, c = \"\", \"\", \"\"\n","    emb1, emb2, emb3 = [0], [0], [0]\n","    for tup in anthologies:\n","        e1 = emb_gn[tup[0]] if a != tup[0] else emb1\n","        e2 = emb_gn[tup[1]] if b != tup[1] else emb2\n","        e3 = emb_gn[tup[2]] if c != tup[2] else emb3\n","        word, sim = find_simi(tup[:3], e1, e2, e3, vocab_gn, emb_gn)\n","        if word == tup[3]:\n","            corrects +=1\n","        total +=1\n","        emb1, emb2, emb3 = e1, e2, e3\n","        a, b, c = tup[0], tup[1], tup[2]\n","        if total % 50 == 0:\n","            print(total, *tup, word, sim, \"actual:\", tup[3], corrects/total)\n","    return corrects, total\n","\n","\n","analogies = get_analogy_ds()\n","vocab_gp = get_vocabulary(fn = GP_GLOVE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cfFL2eQtCLZ","outputId":"2d804653-6fda-4140-d098-0e466b933076"},"outputs":[{"name":"stdout","output_type":"stream","text":["GN GLOVE check\n","50 bangkok thailand hanoi vietnam vietnam 0.6850367252897471 actual: vietnam 0.96\n","100 berlin germany oslo norway norway 0.7555886964501195 actual: norway 0.97\n","150 cairo egypt baghdad iraq iraq 0.7404456221084577 actual: iraq 0.96\n","200 havana cuba islamabad pakistan pakistan 0.7136669378448934 actual: pakistan 0.955\n","250 islamabad pakistan rome italy italy 0.7133663294290572 actual: italy 0.956\n","300 london england berlin germany germany 0.6600025102687568 actual: germany 0.96\n","350 moscow russia kabul afghanistan afghanistan 0.7697258532627865 actual: afghanistan 0.9628571428571429\n","400 paris france tokyo japan japan 0.7510880087797088 actual: japan 0.9625\n","450 stockholm sweden canberra australia australia 0.6283671971970209 actual: australia 0.9644444444444444\n","500 tokyo japan moscow russia russia 0.804189515815529 actual: russia 0.964\n","550 accra ghana apia samoa samoa 0.587528527154653 actual: samoa 0.9636363636363636\n","600 algiers algeria belgrade serbia serbia 0.7395836943844512 actual: serbia 0.9666666666666667\n","650 amman jordan caracas venezuela venezuela 0.6343066126552401 actual: venezuela 0.9661538461538461\n","700 ankara turkey georgetown guyana usa 0.5161205038413887 actual: guyana 0.9614285714285714\n","750 apia samoa beijing china china 0.5874403968686206 actual: china 0.9573333333333334\n","800 ashgabat turkmenistan cairo egypt egypt 0.6421934930335136 actual: egypt 0.955\n","850 asmara eritrea funafuti tuvalu sudan 0.44944100424525335 actual: tuvalu 0.9552941176470588\n","900 athens greece bangkok thailand thailand 0.7736964765091361 actual: thailand 0.9544444444444444\n","950 baghdad iraq budapest hungary hungary 0.7203813032165638 actual: hungary 0.9557894736842105\n","1000 baku azerbaijan dublin ireland ireland 0.6507563144288047 actual: ireland 0.958\n","1050 bamako mali kampala uganda uganda 0.6876933163214406 actual: uganda 0.9580952380952381\n","1100 banjul gambia brussels belgium belgium 0.6111863173516179 actual: belgium 0.9590909090909091\n","1150 beijing china dhaka bangladesh bangladesh 0.6957507888779435 actual: bangladesh 0.9591304347826087\n","1200 beirut lebanon jakarta indonesia indonesia 0.7201674691982409 actual: indonesia 0.9575\n","1250 belmopan belize bishkek kyrgyzstan kyrgyzstan 0.5608389839196148 actual: kyrgyzstan 0.9592\n","1300 berlin germany dakar senegal senegal 0.6086836492105966 actual: senegal 0.9561538461538461\n","1350 bern switzerland helsinki finland finland 0.7176688571983477 actual: finland 0.9525925925925925\n","1400 bishkek kyrgyzstan lima peru peru 0.643139877715715 actual: peru 0.9535714285714286\n","1450 brussels belgium conakry guinea guinea 0.5630548665468632 actual: guinea 0.9544827586206897\n","1500 bucharest romania harare zimbabwe zimbabwe 0.7047509216902758 actual: zimbabwe 0.956\n","1550 budapest hungary libreville gabon gabon 0.5876500314648531 actual: gabon 0.9567741935483871\n","1600 cairo egypt caracas venezuela venezuela 0.7472676279202004 actual: venezuela 0.95375\n","1650 canberra australia georgetown guyana brazil 0.509998549963169 actual: guyana 0.9521212121212121\n","1700 caracas venezuela kigali rwanda rwanda 0.653093188804915 actual: rwanda 0.9505882352941176\n","1750 chisinau moldova manama bahrain bahrain 0.607810181617609 actual: bahrain 0.952\n","1800 copenhagen denmark funafuti tuvalu tuvalu 0.4525388512992872 actual: tuvalu 0.9522222222222222\n","1850 dakar senegal khartoum sudan sudan 0.7766764762249739 actual: sudan 0.9535135135135135\n","1900 damascus syria madrid spain spain 0.6817953331759317 actual: spain 0.9542105263157895\n","1950 doha qatar dublin ireland ireland 0.7157573608873765 actual: ireland 0.9548717948717949\n","2000 dublin ireland kampala uganda uganda 0.6377807645964139 actual: uganda 0.955\n","2050 dushanbe tajikistan luanda angola angola 0.6541363447699113 actual: angola 0.9546341463414634\n","2100 funafuti tuvalu muscat oman oman 0.5203624239124434 actual: oman 0.9547619047619048\n","2150 georgetown guyana jakarta indonesia indonesia 0.6332072165530389 actual: indonesia 0.953953488372093\n","2200 hanoi vietnam ljubljana slovenia slovenia 0.5976454670396814 actual: slovenia 0.9536363636363636\n","2250 harare zimbabwe montevideo uruguay uruguay 0.7273176802893488 actual: uruguay 0.9528888888888889\n","2300 havana cuba paris france france 0.7782320795680001 actual: france 0.9534782608695652\n","2350 islamabad pakistan lima peru peru 0.6400955401491432 actual: peru 0.9536170212765958\n","2400 jakarta indonesia mogadishu somalia somalia 0.7047917546566212 actual: somalia 0.9529166666666666\n","2450 kabul afghanistan ottawa canada canada 0.6261466402229682 actual: canada 0.9526530612244898\n","2500 kathmandu nepal libreville gabon gabon 0.5696851169212083 actual: gabon 0.9532\n","2550 khartoum sudan maputo mozambique mozambique 0.7199227589280155 actual: mozambique 0.9529411764705882\n","2600 kiev ukraine nuuk greenland sisimiut 0.4234290170596016 actual: greenland 0.9523076923076923\n","2650 kigali rwanda skopje macedonia macedonia 0.6441984280891961 actual: macedonia 0.9520754716981132\n","2700 libreville gabon manama bahrain bahrain 0.6091945874078799 actual: bahrain 0.9511111111111111\n","2750 lilongwe malawi nicosia cyprus cyprus 0.5885894282601414 actual: cyprus 0.9505454545454546\n","2800 lima peru roseau dominica dominica 0.41651319955803123 actual: dominica 0.9507142857142857\n","2850 ljubljana slovenia madrid spain spain 0.7454719496780582 actual: spain 0.9508771929824561\n","2900 london england nassau bahamas bahamas 0.4274205297096784 actual: bahamas 0.9510344827586207\n","2950 luanda angola riga latvia latvia 0.6713914406820748 actual: latvia 0.9505084745762712\n","3000 lusaka zambia tegucigalpa honduras honduras 0.6494068482830434 actual: honduras 0.9503333333333334\n","3050 managua nicaragua muscat oman oman 0.6056828196768419 actual: oman 0.9508196721311475\n","3100 manama bahrain quito ecuador ecuador 0.6371036243258152 actual: ecuador 0.9512903225806452\n","3150 manila philippines tashkent uzbekistan uzbekistan 0.7419365584613256 actual: uzbekistan 0.9511111111111111\n","3200 minsk belarus montevideo uruguay uruguay 0.7306038424688043 actual: uruguay 0.9515625\n","3250 mogadishu somalia paris france france 0.6994921329919543 actual: france 0.9516923076923077\n","3300 monrovia liberia taipei taiwan taiwan 0.6484418135359721 actual: taiwan 0.9518181818181818\n","3350 montevideo uruguay valletta malta malta 0.5892291315235689 actual: malta 0.9519402985074626\n","3400 muscat oman ottawa canada canada 0.5411746614576014 actual: canada 0.9523529411764706\n","3450 nairobi kenya stockholm sweden sweden 0.7903301809978667 actual: sweden 0.9521739130434783\n","3500 nassau bahamas tunis tunisia tunisia 0.6089772494881668 actual: tunisia 0.9517142857142857\n","3550 nicosia cyprus nuuk greenland iceland 0.4758010324199632 actual: greenland 0.9515492957746479\n","3600 nouakchott mauritania skopje macedonia macedonia 0.6382886888651763 actual: macedonia 0.9516666666666667\n","3650 nuuk greenland tokyo japan japan 0.6018852094228706 actual: japan 0.952054794520548\n","3700 oslo norway abuja nigeria nigeria 0.6227340403410343 actual: nigeria 0.9524324324324325\n","3750 paramaribo suriname roseau dominica dominica 0.6022057340286601 actual: dominica 0.9528\n","3800 paris france thimphu bhutan bhutan 0.5159315113071343 actual: bhutan 0.9523684210526315\n","3850 podgorica montenegro yerevan armenia armenia 0.6759692021997405 actual: armenia 0.9529870129870129\n","3900 rabat morocco riga latvia latvia 0.662370426675932 actual: latvia 0.9533333333333334\n","3950 riga latvia tegucigalpa honduras honduras 0.6361476187792422 actual: honduras 0.9534177215189873\n","4000 rome italy warsaw poland poland 0.69521179882828 actual: poland 0.9535\n","4050 roseau dominica asmara eritrea eritrea 0.421171908638065 actual: eritrea 0.951604938271605\n","4100 skopje macedonia tashkent uzbekistan uzbekistan 0.6753862757454372 actual: uzbekistan 0.9514634146341463\n","4150 sofia bulgaria vientiane laos laos 0.6153242743242704 actual: laos 0.9518072289156626\n","4200 stockholm sweden apia samoa samoa 0.5311442171479143 actual: samoa 0.9519047619047619\n","4250 suva fiji belgrade serbia serbia 0.6371534584744637 actual: serbia 0.9524705882352941\n","4300 tallinn estonia valletta malta malta 0.6100805721635263 actual: malta 0.9527906976744186\n","4350 tashkent uzbekistan ankara turkey turkey 0.7278485191468383 actual: turkey 0.953103448275862\n","4400 tbilisi georgia beijing china china 0.6325761713719287 actual: china 0.9536363636363636\n"]},{"name":"stdout","output_type":"stream","text":["4450 tehran iran tunis tunisia tunisia 0.7079895477371879 actual: tunisia 0.9539325842696629\n","4500 thimphu bhutan algiers algeria algeria 0.6406752017206051 actual: algeria 0.9544444444444444\n","4550 tirana albania bangkok thailand thailand 0.7156899977305886 actual: thailand 0.9542857142857143\n","4600 tokyo japan budapest hungary hungary 0.7537721199125148 actual: hungary 0.9547826086956521\n","4650 tunis tunisia abuja nigeria nigeria 0.6735391874116704 actual: nigeria 0.9550537634408602\n","4700 vaduz liechtenstein baku azerbaijan azerbaijan 0.6650787422164804 actual: azerbaijan 0.955531914893617\n","4750 valletta malta brussels belgium belgium 0.6951510295571067 actual: belgium 0.9555789473684211\n","4800 vientiane laos yerevan armenia armenia 0.5864594123055564 actual: armenia 0.9558333333333333\n","4850 vilnius lithuania athens greece greece 0.7761045093552832 actual: greece 0.9562886597938144\n","4900 warsaw poland bishkek kyrgyzstan kyrgyzstan 0.6503349714256641 actual: kyrgyzstan 0.9567346938775511\n","4950 windhoek namibia dakar senegal senegal 0.6842655115753754 actual: senegal 0.9567676767676768\n","5000 zagreb croatia asmara eritrea eritrea 0.6126833378366567 actual: eritrea 0.9572\n","5050 algeria dinar mexico peso peso 0.4355316134274658 actual: peso 0.9542574257425742\n","5100 argentina peso japan yen pesos 0.4308884678864612 actual: yen 0.9452941176470588\n","5150 brazil real denmark krone danish 0.5151917813550536 actual: krone 0.9366990291262136\n","5200 bulgaria lev angola kwanza angolan 0.39006277176496096 actual: kwanza 0.9276923076923077\n","5250 canada dollar sweden krona kronor 0.4887320715987559 actual: krona 0.9188571428571428\n","5300 denmark krone mexico peso mexican 0.4342622216711572 actual: peso 0.910188679245283\n","5350 hungary forint japan yen japanese 0.47811590285897326 actual: yen 0.9020560747663552\n","5400 india rupee cambodia riel guilder 0.4410796764936674 actual: riel 0.8955555555555555\n","5450 japan yen algeria dinar algerian 0.4654544214376302 actual: dinar 0.8882568807339449\n","5500 latvia lats russia ruble rubles 0.36769394447500203 actual: ruble 0.8805454545454545\n","5550 lithuania litas latvia lats lats 0.4107245180952553 actual: lats 0.8733333333333333\n","5600 malaysia ringgit europe euro litas 0.33735108945450987 actual: euro 0.8657142857142858\n","5650 nigeria naira bulgaria lev sofia 0.36261078254345186 actual: lev 0.8587610619469026\n","5700 romania leu vietnam dong ninh 0.37637022674844445 actual: dong 0.8515789473684211\n","5750 russia ruble nigeria naira nigerian 0.4141941476298105 actual: naira 0.8446956521739131\n","5800 thailand baht korea won rubles 0.5093003839375225 actual: won 0.8374137931034483\n","5850 usa dollar europe euro currency 0.4952200604957451 actual: euro 0.8305982905982906\n","5900 chicago illinois dallas texas texas 0.5774810233080699 actual: texas 0.8242372881355933\n","5950 houston texas tucson arizona arizona 0.6464654453714138 actual: arizona 0.8238655462184874\n","6000 philadelphia pennsylvania bakersfield california fresno 0.41908227882988625 actual: california 0.8241666666666667\n","6050 dallas texas memphis tennessee tennessee 0.608135522185512 actual: tennessee 0.824793388429752\n","6100 jacksonville florida omaha nebraska nebraska 0.5580684585543589 actual: nebraska 0.8257377049180328\n","6150 indianapolis indiana cincinnati ohio ohio 0.6867050700873093 actual: ohio 0.8261788617886179\n","6200 detroit michigan louisville kentucky kentucky 0.7289818938042022 actual: kentucky 0.8262903225806452\n","6250 memphis tennessee minneapolis minnesota minnesota 0.6727305914280665 actual: minnesota 0.82608\n","6300 boston massachusetts toledo ohio ohio 0.5217547763404832 actual: ohio 0.8258730158730159\n","6350 denver colorado nashville tennessee tennessee 0.6748146639976161 actual: tennessee 0.824251968503937\n","6400 baltimore maryland oakland california california 0.6133442877305305 actual: california 0.825\n","6450 nashville tennessee cincinnati ohio ohio 0.6589487939955969 actual: ohio 0.823875968992248\n","6500 louisville kentucky reno nevada nevada 0.6446799345963066 actual: nevada 0.824\n","6550 portland oregon oakland california california 0.6127992660300162 actual: california 0.8233587786259542\n","6600 tucson arizona anchorage alaska alaska 0.6496890002955482 actual: alaska 0.823030303030303\n","6650 sacramento california miami florida florida 0.6847607491027153 actual: florida 0.8216541353383459\n","6700 mesa arizona orlando florida florida 0.5714244724749877 actual: florida 0.8202985074626866\n","6750 atlanta georgia shreveport louisiana louisiana 0.619492547081798 actual: louisiana 0.8191111111111111\n","6800 miami florida anaheim california california 0.45812657959685127 actual: california 0.8175\n","6850 tulsa oklahoma lubbock texas texas 0.5929424465736975 actual: texas 0.8167883211678832\n","6900 cleveland ohio arlington texas virginia 0.5701543225112128 actual: texas 0.8157971014492753\n","6950 minneapolis minnesota chandler arizona arizona 0.48699612574696804 actual: arizona 0.8149640287769784\n","7000 wichita kansas modesto california california 0.4428017783284197 actual: california 0.8134285714285714\n","7050 bakersfield california toledo ohio ohio 0.5420104112160974 actual: ohio 0.813049645390071\n","7100 tampa florida oxnard california california 0.4718000392377876 actual: california 0.8125352112676056\n","7150 honolulu hawaii henderson nevada campbell 0.46349918902636644 actual: nevada 0.8128671328671329\n","7200 pittsburgh pennsylvania fremont california township 0.45137644930384313 actual: california 0.8120833333333334\n","7250 lexington kentucky worcester massachusetts gloucester 0.49094001545810684 actual: massachusetts 0.8111724137931035\n","7300 cincinnati ohio garland texas judy 0.4109873507795171 actual: texas 0.810958904109589\n","7350 anchorage alaska fontana california nevada 0.3602678923041487 actual: california 0.8107482993197279\n","7400 toledo ohio indianapolis indiana indiana 0.6328966912494992 actual: indiana 0.8110810810810811\n","7450 henderson nevada modesto california fresno 0.5363460462470683 actual: california 0.8099328859060403\n","7500 orlando florida phoenix arizona arizona 0.5858157813661644 actual: arizona 0.8098666666666666\n","7550 chandler arizona irvine california colorado 0.5604020711693976 actual: california 0.8094039735099338\n","7600 madison wisconsin chicago illinois milwaukee 0.6127062121198232 actual: illinois 0.8082894736842106\n","7650 garland texas glendale arizona california 0.5640320106977744 actual: arizona 0.8084967320261438\n","7700 glendale arizona chicago illinois boston 0.6015217493478091 actual: illinois 0.8076623376623376\n","7750 hialeah florida milwaukee wisconsin wisconsin 0.6073755053538685 actual: wisconsin 0.8076129032258065\n","7800 scottsdale arizona shreveport louisiana louisiana 0.6961897145294499 actual: louisiana 0.8078205128205128\n","7850 irving texas memphis tennessee tennessee 0.6624209619520584 actual: tennessee 0.807515923566879\n","7900 irvine california tacoma washington washington 0.591432136640534 actual: washington 0.8055696202531646\n","7950 spokane washington boston massachusetts york 0.6428638751667005 actual: massachusetts 0.8045283018867925\n","8000 shreveport louisiana tacoma washington washington 0.55670838187217 actual: washington 0.80375\n","8050 tacoma washington phoenix arizona arizona 0.5736241328833465 actual: arizona 0.8043478260869565\n","8100 oxnard california tucson arizona arizona 0.7033956480910596 actual: arizona 0.8038271604938272\n","8150 akron ohio houston texas texas 0.6469166702793099 actual: texas 0.8034355828220859\n","8200 amarillo texas portland oregon oregon 0.7033448012777936 actual: oregon 0.8043902439024391\n","8250 glendale california pittsburgh pennsylvania francisco 0.6317208778195071 actual: pennsylvania 0.8032727272727272\n","8300 huntsville alabama denver colorado colorado 0.6120118660195156 actual: colorado 0.8034939759036145\n","8350 worcester massachusetts tulsa oklahoma oklahoma 0.6121504036783004 actual: oklahoma 0.8035928143712575\n","8400 brother sister prince princess princess 0.7719872782271753 actual: princess 0.8042857142857143\n","8450 dad mom brother sister cousin 0.6559403186596322 actual: sister 0.8042603550295858\n","8500 grandpa grandma husband wife wife 0.7268313257977379 actual: wife 0.8047058823529412\n","8550 groom bride stepbrother stepsister stepsister 0.4979790249429397 actual: stepsister 0.8044444444444444\n","8600 his her father mother mother 0.8328274211966129 actual: mother 0.8046511627906977\n"]},{"name":"stdout","output_type":"stream","text":["8650 man woman nephew niece niece 0.7793577951133991 actual: niece 0.8048554913294798\n","8700 policeman policewoman uncle aunt grandfather 0.547061432097489 actual: aunt 0.8050574712643678\n","8750 son daughter grandson granddaughter granddaughter 0.8967902690788242 actual: granddaughter 0.8054857142857142\n","8800 stepbrother stepsister policeman policewoman undercover 0.43563202696466263 actual: policewoman 0.8060227272727273\n","8850 uncle aunt brothers sisters sisters 0.7337796051554695 actual: sisters 0.8063276836158192\n","8900 amazing amazingly usual usually fairly 0.4353555396154974 actual: usually 0.803932584269663\n","8950 calm calmly rapid rapidly industrialization 0.43402225290446295 actual: rapidly 0.8005586592178771\n","9000 complete completely infrequent infrequently totally 0.44946878086069386 actual: infrequently 0.7973333333333333\n","9050 efficient efficiently usual usually occasionally 0.4133883456542893 actual: usually 0.794696132596685\n","9100 free freely rapid rapidly rapidly 0.48413528818485485 actual: rapidly 0.7916483516483517\n","9150 happy happily infrequent infrequently infrequently 0.4121900640449031 actual: infrequently 0.7880874316939891\n","9200 immediate immediately usual usually instead 0.5078179512131364 actual: usually 0.7855434782608696\n","9250 lucky luckily rapid rapidly gradual 0.4566671553889863 actual: rapidly 0.7822702702702703\n","9300 most mostly happy happily entirely 0.4766068392160739 actual: happily 0.7787096774193548\n","9350 occasional occasionally usual usually usually 0.5515020128104637 actual: usually 0.7759358288770053\n","9400 precise precisely rapid rapidly growth 0.4991517713507144 actual: rapidly 0.7725531914893617\n","9450 professional professionally happy happily happily 0.4390804627632897 actual: happily 0.7698412698412699\n","9500 quiet quietly usual usually instead 0.4051506827982778 actual: usually 0.7674736842105263\n","9550 rapid rapidly quick quickly quickly 0.7026651915536577 actual: quickly 0.7649214659685863\n","9600 reluctant reluctantly happy happily happily 0.535514466134168 actual: happily 0.7621875\n","9650 serious seriously usual usually somewhat 0.40708554899515004 actual: usually 0.7595854922279792\n","9700 slow slowly quick quickly quickly 0.6538363656461367 actual: quickly 0.7563917525773196\n","9750 swift swiftly happy happily unhappy 0.4513588583156835 actual: happily 0.7538461538461538\n","9800 unfortunate unfortunately usual usually unlike 0.5232779640007179 actual: usually 0.7512244897959184\n","9850 usual usually quick quickly typically 0.5487124766058143 actual: quickly 0.7482233502538072\n","9900 aware unaware fortunate unfortunate unfortunate 0.4893932520394208 actual: unfortunate 0.7456565656565657\n","9950 clear unclear convenient inconvenient uncertain 0.5098180145223752 actual: inconvenient 0.7423115577889448\n","10000 comfortable uncomfortable certain uncertain particular 0.5108578893269144 actual: uncertain 0.7399\n","10050 consistent inconsistent sure unsure worried 0.5978462958045097 actual: unsure 0.7377114427860697\n","10100 convenient inconvenient productive unproductive unproductive 0.3628033093272816 actual: unproductive 0.7356435643564356\n","10150 efficient inefficient logical illogical logic 0.46096502012452417 actual: illogical 0.7332019704433498\n","10200 fortunate unfortunate informative uninformative humorous 0.4623961951870424 actual: uninformative 0.7313725490196078\n","10250 honest dishonest decided undecided postpone 0.47173233569391765 actual: undecided 0.7288780487804878\n","10300 informative uninformative competitive uncompetitive buiha 0.4041878630426182 actual: uncompetitive 0.7266990291262136\n","10350 known unknown aware unaware unaware 0.7101000781858985 actual: unaware 0.7241545893719806\n","10400 logical illogical responsible irresponsible overseeing 0.43666138732489923 actual: irresponsible 0.7216346153846154\n","10450 possible impossible possibly impossibly apparently 0.5976867398982559 actual: impossibly 0.7198086124401913\n","10500 possibly impossibly informed uninformed insistent 0.4354808381697965 actual: uninformed 0.7172380952380952\n","10550 rational irrational fortunate unfortunate unlucky 0.4964235058960338 actual: unfortunate 0.715260663507109\n","10600 responsible irresponsible convenient inconvenient impractical 0.44391771183403617 actual: inconvenient 0.7133962264150944\n","10650 tasteful distasteful comfortable uncomfortable uncomfortable 0.53330763499012 actual: uncomfortable 0.7113615023474178\n","10700 bad worse small smaller smaller 0.63219829512587 actual: smaller 0.7106542056074766\n","10750 bright brighter easy easier easier 0.6874973586724584 actual: easier 0.7116279069767442\n","10800 cheap cheaper safe safer safer 0.7240479239394728 actual: safer 0.7121296296296297\n","10850 cold colder bad worse worse 0.5315474097227917 actual: worse 0.7129953917050691\n","10900 deep deeper loud louder louder 0.5545689658955815 actual: louder 0.7134862385321101\n","10950 easy easier tough tougher tougher 0.6997352306062667 actual: tougher 0.7142465753424657\n","11000 good better heavy heavier heavier 0.6560564197928965 actual: heavier 0.7150909090909091\n","11050 great greater small smaller smaller 0.6413699584117734 actual: smaller 0.7152941176470589\n","11100 hard harder cool cooler cooler 0.581867154453103 actual: cooler 0.716036036036036\n","11150 high higher safe safer safer 0.5993921161151851 actual: safer 0.7165919282511211\n","11200 hot hotter bad worse worse 0.5097110849262046 actual: worse 0.7174107142857142\n","11250 long longer loud louder hear 0.5275933766367107 actual: louder 0.7178666666666667\n","11300 loud louder tough tougher tougher 0.6046165556799508 actual: tougher 0.7184070796460177\n","11350 low lower great greater upper 0.5342634209446562 actual: greater 0.7185022026431718\n","11400 old older small smaller smaller 0.7152334511594274 actual: smaller 0.716842105263158\n","11450 quick quicker cool cooler cooler 0.685420221997712 actual: cooler 0.7174672489082969\n","11500 safe safer old older older 0.5748112676494124 actual: older 0.7179130434782609\n","11550 short shorter bad worse worse 0.5962039805640654 actual: worse 0.7187878787878788\n","11600 simple simpler large larger larger 0.7593265207545785 actual: larger 0.7195689655172414\n","11650 small smaller tough tougher tougher 0.6516505063528768 actual: tougher 0.7200858369098713\n","11700 smart smarter great greater much 0.46885813276295907 actual: greater 0.7206837606837607\n","11750 strong stronger simple simpler simpler 0.7842071560479894 actual: simpler 0.7211914893617021\n","11800 tight tighter cool cooler cooler 0.562747532114143 actual: cooler 0.7220338983050848\n","11850 tough tougher old older older 0.5121322160866141 actual: older 0.7225316455696202\n","11900 weak weaker bad worse worse 0.6031196279384 actual: worse 0.7233613445378151\n","11950 wide wider large larger larger 0.7355957897831312 actual: larger 0.7241004184100418\n","12000 young younger tall taller taller 0.6408927696041826 actual: taller 0.7244166666666667\n","12050 big biggest long longest longest 0.5441715001205746 actual: longest 0.7230705394190872\n","12100 bright brightest weird weirdest yankovic 0.38050741551233047 actual: weirdest 0.7217355371900827\n","12150 cool coolest quick quickest cruelest 0.38574594661380984 actual: quickest 0.720246913580247\n","12200 dark darkest big biggest biggest 0.47986436110123076 actual: biggest 0.7195901639344262\n","12250 fast fastest slow slowest slowest 0.6161411193059644 actual: slowest 0.7182857142857143\n","12300 good best dark darkest black 0.5808325128528902 actual: darkest 0.7163414634146341\n","12350 high highest strong strongest strongest 0.5867136427362629 actual: strongest 0.7144939271255061\n","12400 hot hottest great greatest greatest 0.4203759149807548 actual: greatest 0.7131451612903226\n","12450 long longest warm warmest warmest 0.430645134049082 actual: warmest 0.712289156626506\n","12500 low lowest long longest longest 0.5895959919143975 actual: longest 0.71192\n","12550 old oldest young youngest youngest 0.6058919272340113 actual: youngest 0.7101195219123506\n","12600 sharp sharpest simple simplest simplest 0.4978374616846669 actual: simplest 0.7088095238095238\n","12650 simple simplest cold coldest colder 0.44560112932886736 actual: coldest 0.7077470355731226\n","12700 slow slowest smart smartest smartest 0.41950259213939484 actual: smartest 0.7069291338582677\n","12750 small smallest fast fastest fastest 0.4981522227434831 actual: fastest 0.7063529411764706\n"]},{"name":"stdout","output_type":"stream","text":["12800 strange strangest tall tallest tallest 0.5075045533868683 actual: tallest 0.706328125\n","12850 strong strongest hot hottest billboard 0.516695918773027 actual: hottest 0.7059922178988327\n","12900 tall tallest weird weirdest rarest 0.370394211672587 actual: weirdest 0.7055038759689922\n","12950 tasty tastiest lucky luckiest igbinedion 0.41092592835639336 actual: luckiest 0.7044015444015445\n","13000 weak weakest big biggest biggest 0.48262939118394593 actual: biggest 0.7028461538461539\n","13050 weird weirdest simple simplest simplest 0.43059809798332216 actual: simplest 0.7022988505747126\n","13100 young youngest dark darkest darker 0.4597670122949482 actual: darkest 0.7012977099236641\n","13150 code coding see seeing perceptual 0.36208053735609247 actual: seeing 0.6999239543726236\n","13200 debug debugging increase increasing increased 0.61995257558958 actual: increasing 0.6991666666666667\n","13250 decrease decreasing vanish vanishing vanishes 0.5576561961973672 actual: vanishing 0.6988679245283019\n","13300 discover discovering predict predicting predicting 0.7869050063700165 actual: predicting 0.6984962406015037\n","13350 enhance enhancing describe describing describing 0.7131516239849037 actual: describing 0.6985767790262172\n","13400 generate generating sing singing sang 0.6792848147269217 actual: singing 0.6985820895522388\n","13450 implement implementing jump jumping jumps 0.5454657101002875 actual: jumping 0.6985873605947955\n","13500 increase increasing write writing writing 0.6300867718144768 actual: writing 0.6986666666666667\n","13550 jump jumping run running running 0.5821432996162527 actual: running 0.6989667896678967\n","13600 listen listening enhance enhancing enhancing 0.7011393491429356 actual: enhancing 0.6988235294117647\n","13650 move moving slow slowing fast 0.6438854466603093 actual: slowing 0.6986813186813187\n","13700 play playing jump jumping jumps 0.5361547314762498 actual: jumping 0.6983941605839417\n","13750 read reading dance dancing dancing 0.6641444637521123 actual: dancing 0.6982545454545455\n","13800 say saying scream screaming shout 0.4765379417584307 actual: screaming 0.6983333333333334\n","13850 scream screaming generate generating generating 0.5248824509285108 actual: generating 0.6976895306859205\n","13900 shuffle shuffling think thinking really 0.606224242516307 actual: thinking 0.6976258992805755\n","13950 sing singing look looking looking 0.657315610629364 actual: looking 0.6970609318996416\n","14000 slow slowing decrease decreasing decreasing 0.6532623693626245 actual: decreasing 0.6968571428571428\n","14050 swim swimming scream screaming primal 0.4098557038427904 actual: screaming 0.69644128113879\n","14100 vanish vanishing implement implementing implementing 0.5378756109741183 actual: implementing 0.6958156028368795\n","14150 walk walking think thinking really 0.6045117108684467 actual: thinking 0.6954770318021202\n","14200 albania albanian greece greek greek 0.7324477879000106 actual: greek 0.6956338028169015\n","14250 argentina argentinean netherlands dutch dutch 0.5492525252468656 actual: dutch 0.6964210526315789\n","14300 australia australian albania albanian albanian 0.7173282646291366 actual: albanian 0.6972727272727273\n","14350 belarus belorussian france french french 0.4876288679131197 actual: french 0.697979094076655\n","14400 brazil brazilian mexico mexican mexican 0.7989213851273744 actual: mexican 0.6986805555555555\n","14450 bulgaria bulgarian thailand thai thai 0.7526127212528049 actual: thai 0.6995155709342561\n","14500 chile chilean egypt egyptian egyptian 0.7955662771523495 actual: egyptian 0.7002068965517242\n","14550 china chinese macedonia macedonian macedonian 0.7223404231328638 actual: macedonian 0.7010309278350515\n","14600 colombia colombian sweden swedish swedish 0.8028209129132559 actual: swedish 0.7017808219178082\n","14650 croatia croatian chile chilean chilean 0.7961708787930499 actual: chilean 0.702457337883959\n","14700 egypt egyptian japan japanese japanese 0.7970688269739887 actual: japanese 0.703265306122449\n","14750 england english slovakia slovakian slovak 0.6793366397345271 actual: slovakian 0.704\n","14800 france french bulgaria bulgarian bulgarian 0.7412380685322284 actual: bulgarian 0.7046621621621622\n","14850 greece greek israel israeli israeli 0.6921027806174666 actual: israeli 0.7054545454545454\n","14900 iceland icelandic portugal portuguese portuguese 0.7452431976476463 actual: portuguese 0.7062416107382551\n","14950 india indian belarus belorussian belarusian 0.6160798034043187 actual: belorussian 0.7068227424749164\n","15000 ireland irish germany german german 0.8044428818976984 actual: german 0.7076\n","15050 italy italian peru peruvian peruvian 0.735370808114437 actual: peruvian 0.7083720930232558\n","15100 japan japanese australia australian australian 0.7955515942753999 actual: australian 0.7090066225165563\n","15150 korea korean england english english 0.7296058625776933 actual: english 0.7097029702970297\n","15200 malta maltese netherlands dutch dutch 0.6284860087771207 actual: dutch 0.7104605263157895\n","15250 mexico mexican albania albanian albanian 0.7310674982937054 actual: albanian 0.7111475409836066\n","15300 moldova moldovan denmark danish danish 0.6891541747694271 actual: danish 0.711764705882353\n","15350 netherlands dutch korea korean korean 0.8108443243827114 actual: korean 0.7125081433224756\n","15400 peru peruvian thailand thai thai 0.7119784378795688 actual: thai 0.7131818181818181\n","15450 poland polish colombia colombian colombian 0.7739088302060295 actual: colombian 0.7137864077669903\n","15500 portugal portuguese italy italian italian 0.8441849614140882 actual: italian 0.714516129032258\n","15550 slovakia slovakian sweden swedish swedish 0.7065996127387684 actual: swedish 0.71524115755627\n","15600 spain spanish chile chilean chilean 0.7379936963516767 actual: chilean 0.7158974358974359\n","15650 sweden swedish ireland irish irish 0.8100284713777307 actual: irish 0.7166773162939297\n","15700 switzerland swiss poland polish polish 0.7631696815069433 actual: polish 0.7173885350318472\n","15750 ukraine ukrainian bulgaria bulgarian bulgarian 0.7897892305922444 actual: bulgarian 0.7179047619047619\n","15800 dancing danced paying paid paid 0.5366624841129011 actual: paid 0.7180379746835444\n","15850 decreasing decreased sleeping slept sleep 0.5343266474510403 actual: slept 0.717981072555205\n","15900 enhancing enhanced falling fell fell 0.6089927944567939 actual: fell 0.7172327044025157\n","15950 falling fell looking looked looked 0.7526201081028765 actual: looked 0.7164263322884012\n","16000 feeding fed singing sang sang 0.5021578567152719 actual: sang 0.7164375\n","16050 flying flew dancing danced danced 0.5867603522438983 actual: danced 0.7159501557632398\n","16100 going went knowing knew knew 0.5677500202745577 actual: knew 0.71472049689441\n","16150 hiding hid selling sold sold 0.611496246312959 actual: sold 0.7142414860681114\n","16200 hitting hit walking walked walk 0.6121814887716911 actual: walked 0.7133950617283951\n","16250 implementing implemented hitting hit hit 0.6374993463560246 actual: hit 0.7126153846153847\n","16300 jumping jumped screaming screamed screams 0.49218145439016825 actual: screamed 0.7122085889570552\n","16350 knowing knew thinking thought thought 0.7402079408142055 actual: thought 0.7118042813455657\n","16400 listening listened going went go 0.5690673304183714 actual: went 0.7110975609756097\n","16450 moving moved running ran ran 0.7575328851886881 actual: ran 0.7108814589665654\n","16500 paying paid swimming swam pool 0.607418389872073 actual: swam 0.7106666666666667\n","16550 playing played flying flew flew 0.6206368772964026 actual: flew 0.7100302114803625\n","16600 predicting predicted paying paid paid 0.7381109029535675 actual: paid 0.7093975903614458\n","16650 running ran spending spent spent 0.6656185826152037 actual: spent 0.7083483483483484\n","16700 saying said falling fell fell 0.7165073190618567 actual: fell 0.7079041916167664\n","16750 screaming screamed looking looked looked 0.5484629645222995 actual: looked 0.7075820895522388\n","16800 selling sold sleeping slept room 0.44297910623698167 actual: slept 0.707202380952381\n","16850 shrinking shrank describing described describes 0.5060526690011949 actual: described 0.7068842729970326\n","16900 singing sang knowing knew knows 0.595744678596799 actual: knew 0.7063905325443787\n","16950 sitting sat selling sold sold 0.6374763763033658 actual: sold 0.7060766961651918\n"]},{"name":"stdout","output_type":"stream","text":["17000 slowing slowed dancing danced dance 0.6332133366558019 actual: danced 0.7054117647058824\n","17050 spending spent increasing increased increased 0.615547068293956 actual: increased 0.7051026392961877\n","17100 striking struck screaming screamed screams 0.4855845047339877 actual: screamed 0.7047953216374269\n","17150 taking took walking walked walk 0.6018770967001634 actual: walked 0.7041399416909621\n","17200 thinking thought hitting hit hit 0.6038662563281537 actual: hit 0.7038953488372093\n","17250 vanishing vanished running ran ran 0.5933227972472171 actual: ran 0.7036521739130435\n","17300 walking walked swimming swam swam 0.5411557464052763 actual: swam 0.7033526011560693\n","17350 banana bananas color colors colour 0.6522338226554668 actual: colors 0.7027089337175793\n","17400 bird birds machine machines machines 0.6754873897140109 actual: machines 0.7032183908045977\n","17450 bottle bottles bird birds birds 0.640972884498438 actual: birds 0.7033810888252149\n","17500 car cars finger fingers fingers 0.6527065592373466 actual: fingers 0.7034285714285714\n","17550 cat cats rat rats rats 0.7256009430534387 actual: rats 0.7037037037037037\n","17600 cloud clouds donkey donkeys donkeys 0.37430497362824566 actual: donkeys 0.7039204545454546\n","17650 color colors mouse mice mickey 0.5076642646500715 actual: mice 0.7038526912181303\n","17700 computer computers child children children 0.6507290812486458 actual: children 0.703954802259887\n","17750 dog dogs machine machines machines 0.7053039218310131 actual: machines 0.7043943661971831\n","17800 dollar dollars bird birds birds 0.5527659238549909 actual: birds 0.7043258426966292\n","17850 dream dreams finger fingers fingers 0.7116341744774335 actual: fingers 0.704873949579832\n","17900 eagle eagles rat rats rats 0.48947093094855604 actual: rats 0.7045251396648045\n","17950 elephant elephants dog dogs dogs 0.7702463235628328 actual: dogs 0.7049025069637883\n","18000 finger fingers mouse mice mickey 0.5375146267381354 actual: mice 0.7047777777777777\n","18050 goat goats child children children 0.6363125462093275 actual: children 0.7047645429362881\n","18100 horse horses machine machines machines 0.6831176226928429 actual: machines 0.7047513812154697\n","18150 lion lions bird birds birds 0.60952527341065 actual: birds 0.7050137741046832\n","18200 machine machines elephant elephants elephants 0.6170830622692856 actual: elephants 0.7051648351648352\n","18250 man men rat rats rats 0.5827313918817263 actual: rats 0.705041095890411\n","18300 melon melons dog dogs dogs 0.5426438878282787 actual: dogs 0.7053005464480875\n","18350 monkey monkeys melon melons pumpkins 0.34947948208203305 actual: melons 0.705449591280654\n","18400 onion onions child children children 0.5967205402700176 actual: children 0.7055434782608696\n","18450 pear pears horse horses horses 0.6448291167197101 actual: horses 0.7057452574525745\n","18500 pineapple pineapples bird birds birds 0.5341183427083072 actual: birds 0.7058918918918919\n","18550 rat rats elephant elephants elephants 0.6440763378418805 actual: elephants 0.7063611859838275\n","18600 road roads pig pigs pigs 0.5146584891325166 actual: pigs 0.7064516129032258\n","18650 woman women dog dogs dogs 0.6788461909151197 actual: dogs 0.7069168900804289\n","18700 decrease decreases vanish vanishes vanishes 0.6368573632942426 actual: vanishes 0.7067379679144385\n","18750 eat eats sit sits sits 0.6036688744886185 actual: sits 0.7061866666666666\n","18800 estimate estimates say says says 0.6624446586067301 actual: says 0.7060106382978724\n","18850 generate generates implement implements implementing 0.638725744484908 actual: implements 0.7056233421750663\n","18900 go goes decrease decreases decreases 0.7602826553463632 actual: decreases 0.7058201058201058\n","18950 increase increases talk talks talking 0.5537660970770866 actual: talks 0.7053298153034301\n","19000 play plays shuffle shuffles ālī 0.30899807422184566 actual: shuffles 0.7052631578947368\n","19050 predict predicts listen listens says 0.4544840097130577 actual: listens 0.7049343832020998\n","19100 say says estimate estimates estimates 0.691203741316331 actual: estimates 0.7048167539267016\n","19150 search searches work works works 0.5865598257913914 actual: works 0.7042297650130548\n","19200 shuffle shuffles speak speaks speaks 0.52594736014073 actual: speaks 0.7036979166666667\n","19250 sing sings say says says 0.6795610019458919 actual: says 0.7035844155844155\n","19300 slow slows implement implements executes 0.4272343288306233 actual: implements 0.7034715025906736\n","19350 swim swims eat eats eats 0.649139226399494 actual: eats 0.7035658914728682\n","19400 think thinks vanish vanishes vanishes 0.5924305530057272 actual: vanishes 0.7027835051546392\n","19450 vanish vanishes shuffle shuffles ipod 0.3375063214971166 actual: shuffles 0.7024164524421593\n","19500 work works predict predicts analyze 0.5572309146822916 actual: predicts 0.7017435897435897\n","Final score: 0.7014940646745804 13710 19544\n"]}],"source":["##################################################################\n","# It might take up to 48 hours to reproduce Google anthology tests !!\n","# you can run 2 next cells to verify results for 67 and 400 rows\n","#####################################################################\n","\n","print(f\"GN GLOVE check\")\n","corrects, total = calculate_acc_for_analogies(analogies, emb_gn, vocab_gp)\n","print(f\"Final score: {corrects/total} {corrects} {total}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lgXLoxu6295"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9yUwxRC6296","executionInfo":{"status":"ok","timestamp":1651252346183,"user_tz":0,"elapsed":749042,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}},"outputId":"c53da52d-8dfd-4167-c7a9-a760aaff57bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["GP-GLOVE check\n","8800 stepbrother stepsister policeman policewoman undercover 0.43563202696466263 actual: policewoman 0.8060227272727273\n","8867 uncle aunt stepbrother stepsister stepmother 0.529885949010886 actual: stepsister 0.8065862185632119\n","GP-GLOVE accuracy of sem analogies: 0.8065862185632119 7152 8867\n","GP-GLOVE accuracy of syn analogies: 0.6142174768193313 correct answers: 6558\n","GP-GLOVE overal accuracy for analogies: 0.7014940646745804 \n"]}],"source":["# Test for semantic analogies using previous results printed above\n","corrects, total = 13710, 19544\n","\n","def calculate_acc_for_sem_analogies(analogies, emb_gn, vocab_gn):\n","    \"\"\" check accuracy of sem analogies\n","        initial accuracy was taken from row '8800 ...' of previous cell\n","    \"\"\"\n","    previous_res = \"8800 stepbrother stepsister policeman policewoman undercover 0.43563202696466263 actual: policewoman 0.8060227272727273\"\n","    print(previous_res)\n","    total = 8800\n","    corrects = int(0.8060227272727273 * total)\n","    a, b, c = \"\", \"\", \"\"\n","    emb1, emb2, emb3 = [0], [0], [0]\n","    for tup in analogies[8800:8867]:\n","        # saving vectors to speed up computation\n","        e1 = emb_gn[tup[0]] if a != tup[0] else emb1\n","        e2 = emb_gn[tup[1]] if b != tup[1] else emb2\n","        e3 = emb_gn[tup[2]] if c != tup[2] else emb3\n","        # trying to find similar word as argmax(3COSADD(e2-e1+e3, E(w))) for all words w in vocab except tup[:3]\n","        word, sim = find_simi(tup[:3], e1, e2, e3, vocab_gn, emb_gn)\n","        if word == tup[3]:\n","            corrects +=1\n","        total +=1\n","        emb1, emb2, emb3 = e1, e2, e3\n","        a, b, c = tup[0], tup[1], tup[2]\n","        if total % 200 == 0:\n","            print(total, *tup, word, sim, \"actual:\", tup[3], corrects/total)\n","    print(total, *tup, word, sim, \"actual:\", tup[3], corrects/total)\n","    return corrects , total\n","\n","print(f\"GP-GLOVE check\")\n","sem_corrects, sem_total = calculate_acc_for_sem_analogies(analogies, emb_gn, vocab_gp)\n","print(f\"GP-GLOVE accuracy of sem analogies: {sem_corrects/sem_total} {sem_corrects} {sem_total}\")\n","syn_acc = (corrects - sem_corrects) / (total - sem_total)\n","print(f\"GP-GLOVE accuracy of syn analogies: {syn_acc} correct answers: {corrects - sem_corrects}\")\n","print(f\"GP-GLOVE overal accuracy for analogies: {corrects / total} \")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPS0EhKP6298","executionInfo":{"status":"ok","timestamp":1651247628297,"user_tz":0,"elapsed":249,"user":{"displayName":"Pavel Evgenievich Bystrov","userId":"14152123446971396759"}}},"outputs":[],"source":["# Test for semantic analogies using previous results printed above\n","def calculate_acc_for_400(analogies, emb_gn, vocab_gn):\n","    \"\"\" check accuracy of sem analogies\n","        initial accuracy was taken from row '8800 ...' of previous cell\n","    \"\"\"\n","    total = 0\n","    corrects = 0\n","    a, b, c = \"\", \"\", \"\"\n","    emb1, emb2, emb3 = [0], [0], [0]\n","    for tup in analogies[:400]:\n","        # saving vectors to speed up computation\n","        e1 = emb_gn[tup[0]] if a != tup[0] else emb1\n","        e2 = emb_gn[tup[1]] if b != tup[1] else emb2\n","        e3 = emb_gn[tup[2]] if c != tup[2] else emb3\n","        # trying to find similar word as argmax(3COSADD(e2-e1+e3, E(w))) for all words w in vocab except tup[:3]\n","        word, sim = find_simi(tup[:3], e1, e2, e3, vocab_gn, emb_gn)\n","        if word == tup[3]:\n","            corrects +=1\n","        total +=1\n","        emb1, emb2, emb3 = e1, e2, e3\n","        a, b, c = tup[0], tup[1], tup[2]\n","        if total % 200 == 0:\n","            print(total, *tup, word, sim, \"actual:\", tup[3], corrects/total)\n","    print(total, *tup, word, sim, \"actual:\", tup[3], corrects/total)\n","    return corrects , total\n","\n","sem_corrects, sem_total = calculate_acc_for_400(analogies, emb_gn, vocab_gp)\n","print(f\"GP-GLOVE accuracy of 400 sem analogies: {sem_corrects/sem_total} {sem_corrects} {sem_total}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YTUjLT336298"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"debiassing_anthology_analysis_gp_glove.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}