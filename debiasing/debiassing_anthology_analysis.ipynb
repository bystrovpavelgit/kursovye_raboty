{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOkGiJEun0P8",
    "outputId": "3216a079-dcd4-47f6-c1ea-55b85be8c824"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNpMntKbn0Xm",
    "outputId": "b365e07e-b999-4cf2-efdd-4276e8ca2ec9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McJin_jin0bG",
    "outputId": "abba05c7-2f99-4c88-fb88-9a5115e64230"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLCBcVmttCD4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bhzgHUMktCGd"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import KeyedVectors\n",
    "import argparse\n",
    "import time\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "SEM_BIAS = './SemBias/SemBias'\n",
    "GP_GN = '/media/pavel/tmp/glove/gp_gn.txt'\n",
    "GP = '/media/pavel/tmp/glove/vectors300.txt'\n",
    "GLOVE = '/media/pavel/tmp/glove/gp_glove.txt'\n",
    "GOOGLE_ANT = '/media/pavel/tmp/glove/google_anthology_ds.txt'\n",
    "RG65 = '/media/pavel/tmp/glove/EN-RG-65.txt'\n",
    "WSA = '/media/pavel/tmp/glove/WS_A.csv'\n",
    "WSB = '/media/pavel/tmp/glove/WS_B.csv'\n",
    "MTURK = '/media/pavel/tmp/glove/MTurk.csv'\n",
    "RW = '/media/pavel/tmp/glove/RW2034.csv'\n",
    "MEN = '/media/pavel/tmp/glove/MEN3000.csv'\n",
    "SIMLEX = '/media/pavel/tmp/glove/SimLex.txt'\n",
    "SEM_EVAL = '/media/pavel/tmp/glove/SemEval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_gp_gn = KeyedVectors.load_word2vec_format(GP_GN, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "h5yMzk8YtCI5"
   },
   "outputs": [],
   "source": [
    "def get_vocabulary(fn = GLOVE):\n",
    "    with open(fn, \"r\") as f:\n",
    "        vocab = [line.lower().split()[0] for line in f]\n",
    "    return vocab[1:]\n",
    "\n",
    "\n",
    "def get_anthology_ds(fn = GOOGLE_ANT):\n",
    "    with open(fn, \"r\") as f:\n",
    "        vocab = [line.lower().split() for line in f if line[0] != ':']\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def get_semeval(path = SEM_EVAL):\n",
    "    fnames = Path(path).rglob(\"*.txt\")\n",
    "    full_lst = []\n",
    "    for n in fnames:\n",
    "        pth = str(n)\n",
    "        with open(pth, \"r\") as f:\n",
    "            vocab = [line.replace('\"', \"\").lower().split() for line in f if line[0] != '#']\n",
    "        full_lst = full_lst + vocab\n",
    "    res = [[p[0].split(':')] + [p[1].split(':')]+[p[2].split(':')] + [p[3].split(':')] for p in full_lst]\n",
    "    return res\n",
    "\n",
    "\n",
    "def cosmul_sim(w, a, b, c, to_do, eps = 0.01):\n",
    "    \"\"\" 3COSMUL similarity \"\"\"\n",
    "    if to_do:\n",
    "        print(cos(w, c), cos(w, b), cos(w, a))\n",
    "    c1, c2, c3 = cos(w, c), cos(w, b), cos(w, a)\n",
    "    if to_do:\n",
    "        print(c1, c2, c3, (c1 * c2)/(c3 + eps))\n",
    "    if c3 < 0:\n",
    "        eps = -0.01\n",
    "    return c1 * c2/(c3 + eps)\n",
    "\n",
    "def cosine_sim(v, w, eps = 0.001, eps2 = 0.000001):\n",
    "    \"\"\"cosine similarity with numerical overflow protection or 3COSADD similarity\"\"\"\n",
    "    return np.dot(w, v)/((np.linalg.norm(w) + eps2) * (np.linalg.norm(v) + eps))\n",
    "\n",
    "\n",
    "def find_simi(lst, a, b, c, vocab, emb):\n",
    "    \"\"\"find argmax using 3COSADD method\"\"\"\n",
    "    v1 = b - a + c\n",
    "    amax = 0.\n",
    "    result = \"\"\n",
    "    for w2 in vocab:\n",
    "        if w2 not in lst:\n",
    "            sim = cosine_sim(emb[w2], v1)\n",
    "            if sim > amax:\n",
    "                result = w2\n",
    "                amax = sim\n",
    "    return result, amax\n",
    "\n",
    "#anth_semeval = get_semeval()\n",
    "anthologies = get_anthology_ds()\n",
    "vocab_gp_gn = get_vocabulary(fn = GP_GN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3cfFL2eQtCLZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 havana cuba islamabad pakistan pakistan 0.6373196279240257 actual: pakistan 0.96\n",
      "400 paris france tokyo japan japan 0.6296925698790207 actual: japan 0.965\n",
      "600 algiers algeria belgrade serbia serbia 0.708826016842488 actual: serbia 0.97\n",
      "800 ashgabat turkmenistan cairo egypt egypt 0.595151121535518 actual: egypt 0.9675\n",
      "1000 baku azerbaijan dublin ireland ireland 0.5962528090608104 actual: ireland 0.972\n",
      "1200 beirut lebanon jakarta indonesia indonesia 0.6490071423248388 actual: indonesia 0.9725\n",
      "1400 bishkek kyrgyzstan lima peru peru 0.5495437757975783 actual: peru 0.9707142857142858\n",
      "1600 cairo egypt caracas venezuela venezuela 0.7132207770556203 actual: venezuela 0.969375\n",
      "1800 copenhagen denmark funafuti tuvalu tuvalu 0.46459788067411767 actual: tuvalu 0.9688888888888889\n",
      "2000 dublin ireland kampala uganda uganda 0.6038106880559133 actual: uganda 0.9705\n",
      "2200 hanoi vietnam ljubljana slovenia slovenia 0.5541343648369021 actual: slovenia 0.9686363636363636\n",
      "2400 jakarta indonesia mogadishu somalia somalia 0.6780990658261742 actual: somalia 0.9679166666666666\n",
      "2600 kiev ukraine nuuk greenland iceland 0.40000130409850637 actual: greenland 0.9661538461538461\n",
      "2800 lima peru roseau dominica dominica 0.44465911647075673 actual: dominica 0.9635714285714285\n",
      "3000 lusaka zambia tegucigalpa honduras honduras 0.6441629505448491 actual: honduras 0.9626666666666667\n",
      "3200 minsk belarus montevideo uruguay uruguay 0.7333963502925189 actual: uruguay 0.9634375\n",
      "3400 muscat oman ottawa canada toronto 0.431938070610503 actual: canada 0.9623529411764706\n",
      "3600 nouakchott mauritania skopje macedonia macedonia 0.6640288426759562 actual: macedonia 0.9602777777777778\n",
      "3800 paris france thimphu bhutan bhutan 0.47523856173428114 actual: bhutan 0.96\n",
      "4000 rome italy warsaw poland poland 0.6169038776631433 actual: poland 0.9605\n",
      "4200 stockholm sweden apia samoa samoa 0.524343285592901 actual: samoa 0.9576190476190476\n",
      "4400 tbilisi georgia beijing china china 0.5279072138828167 actual: china 0.9586363636363636\n",
      "4600 tokyo japan budapest hungary hungary 0.6681144503531204 actual: hungary 0.9595652173913043\n",
      "4800 vientiane laos yerevan armenia armenia 0.5765981820224497 actual: armenia 0.96125\n",
      "5000 zagreb croatia asmara eritrea eritrea 0.5868576743703237 actual: eritrea 0.9628\n",
      "5200 bulgaria lev angola kwanza angolan 0.406322030776092 actual: kwanza 0.9328846153846154\n",
      "5400 india rupee cambodia riel shilling 0.44978944860533104 actual: riel 0.9012962962962963\n",
      "5600 malaysia ringgit europe euro saceur 0.29430337232778697 actual: euro 0.8714285714285714\n",
      "5800 thailand baht korea won rmb 0.48968230268170404 actual: won 0.843103448275862\n",
      "6000 philadelphia pennsylvania bakersfield california fresno 0.38431282274472633 actual: california 0.8296666666666667\n",
      "6200 detroit michigan louisville kentucky kentucky 0.6364325682579873 actual: kentucky 0.8287096774193549\n",
      "6400 baltimore maryland oakland california california 0.4857728484338129 actual: california 0.82390625\n",
      "6600 tucson arizona anchorage alaska alaska 0.5947009981468523 actual: alaska 0.8183333333333334\n",
      "6800 miami florida anaheim california california 0.41869847994193476 actual: california 0.8101470588235294\n",
      "7000 wichita kansas modesto california fresno 0.40932464428248655 actual: california 0.804\n",
      "7200 pittsburgh pennsylvania fremont california wyoming 0.39426859058359603 actual: california 0.8005555555555556\n",
      "7400 toledo ohio indianapolis indiana indiana 0.48377784197598245 actual: indiana 0.7972972972972973\n",
      "7600 madison wisconsin chicago illinois milwaukee 0.5523532710202668 actual: illinois 0.7932894736842105\n",
      "7800 scottsdale arizona shreveport louisiana louisiana 0.6085569596708524 actual: louisiana 0.7897435897435897\n",
      "8000 shreveport louisiana tacoma washington washington 0.41432606396247135 actual: washington 0.78375\n",
      "8200 amarillo texas portland oregon oregon 0.5932511820561335 actual: oregon 0.7829268292682927\n",
      "8400 brother sister prince princess princess 0.7709663158315151 actual: princess 0.7814285714285715\n",
      "8600 his her father mother mother 0.8050790041483592 actual: mother 0.7827906976744186\n",
      "8800 stepbrother stepsister policeman policewoman boyfriend 0.6182800965333808 actual: policewoman 0.7822727272727272\n",
      "9000 complete completely infrequent infrequently totally 0.4302591510404601 actual: infrequently 0.7735555555555556\n",
      "9200 immediate immediately usual usually instead 0.38542226142042674 actual: usually 0.7618478260869566\n",
      "9400 precise precisely rapid rapidly industrialisation 0.41085957862602956 actual: rapidly 0.7491489361702127\n",
      "9600 reluctant reluctantly happy happily happily 0.4873493565367646 actual: happily 0.7392708333333333\n",
      "9800 unfortunate unfortunately usual usually however 0.35954687403060637 actual: usually 0.7292857142857143\n",
      "10000 comfortable uncomfortable certain uncertain inappropriate 0.4190050216613013 actual: uncertain 0.7185\n",
      "10200 fortunate unfortunate informative uninformative humorous 0.4391603008980662 actual: uninformative 0.7107843137254902\n",
      "10400 logical illogical responsible irresponsible overseeing 0.40252629112607224 actual: irresponsible 0.7024038461538461\n",
      "10600 responsible irresponsible convenient inconvenient excuse 0.44411184855108 actual: inconvenient 0.6941509433962264\n",
      "10800 cheap cheaper safe safer safer 0.7030555093762199 actual: safer 0.692962962962963\n",
      "11000 good better heavy heavier heavier 0.5699381666250672 actual: heavier 0.696\n",
      "11200 hot hotter bad worse worse 0.4734013753178901 actual: worse 0.6980357142857143\n",
      "11400 old older small smaller smaller 0.577255517526037 actual: smaller 0.6989473684210527\n",
      "11600 simple simpler large larger larger 0.6660387681876334 actual: larger 0.7017241379310345\n",
      "11800 tight tighter cool cooler warmer 0.5075879516617492 actual: cooler 0.7041525423728814\n",
      "12000 young younger tall taller taller 0.5807366922974414 actual: taller 0.7063333333333334\n",
      "12200 dark darkest big biggest biggest 0.40407962751766396 actual: biggest 0.7025409836065574\n",
      "12400 hot hottest great greatest greatest 0.40474947029274216 actual: greatest 0.6970161290322581\n",
      "12600 sharp sharpest simple simplest simplest 0.46887258202756116 actual: simplest 0.6930952380952381\n",
      "12800 strange strangest tall tallest tallest 0.48678638727337653 actual: tallest 0.690859375\n",
      "13000 weak weakest big biggest biggest 0.4553939428367259 actual: biggest 0.6867692307692308\n",
      "13200 debug debugging increase increasing increased 0.5471543147288777 actual: increasing 0.683030303030303\n",
      "13400 generate generating sing singing singing 0.5858519687365615 actual: singing 0.6820149253731344\n",
      "13600 listen listening enhance enhancing enhancing 0.6657498937041186 actual: enhancing 0.6813235294117647\n",
      "13800 say saying scream screaming shout 0.5049564804090793 actual: screaming 0.6801449275362319\n",
      "14000 slow slowing decrease decreasing decreasing 0.6338996424774423 actual: decreasing 0.6780714285714285\n",
      "14200 albania albanian greece greek greek 0.6053935869426497 actual: greek 0.6763380281690141\n",
      "14400 brazil brazilian mexico mexican mexican 0.6996871332512182 actual: mexican 0.6791666666666667\n",
      "14600 colombia colombian sweden swedish swedish 0.7318987112236565 actual: swedish 0.6824657534246575\n",
      "14800 france french bulgaria bulgarian bulgarian 0.7023212526872652 actual: bulgarian 0.6855405405405406\n",
      "15000 ireland irish germany german german 0.6616417960634192 actual: german 0.6886666666666666\n",
      "15200 malta maltese netherlands dutch dutch 0.5541257994673578 actual: dutch 0.6917763157894737\n",
      "15400 peru peruvian thailand thai thai 0.657726265661737 actual: thai 0.6946753246753247\n",
      "15600 spain spanish chile chilean chilean 0.6500620039382342 actual: chilean 0.6975641025641026\n",
      "15800 dancing danced paying paid pay 0.5344848935828315 actual: paid 0.699873417721519\n",
      "16000 feeding fed singing sang sang 0.4746022856734373 actual: sang 0.69825\n",
      "16200 hitting hit walking walked walk 0.5009153355819171 actual: walked 0.6958024691358025\n",
      "16400 listening listened going went go 0.46943272633036787 actual: went 0.6945731707317073\n",
      "16600 predicting predicted paying paid pay 0.6615704085585153 actual: paid 0.6939156626506024\n",
      "16800 selling sold sleeping slept slept 0.4304974090926881 actual: slept 0.6920238095238095\n",
      "17000 slowing slowed dancing danced dancers 0.521381536884436 actual: danced 0.6911764705882353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17200 thinking thought hitting hit hit 0.45592083463097943 actual: hit 0.6898837209302325\n",
      "17400 bird birds machine machines machines 0.6135082378812335 actual: machines 0.6897701149425287\n",
      "17600 cloud clouds donkey donkeys donkeys 0.3652489444464547 actual: donkeys 0.690625\n",
      "17800 dollar dollars bird birds birds 0.4779135821040585 actual: birds 0.6906741573033708\n",
      "18000 finger fingers mouse mice mickey 0.5046365748423155 actual: mice 0.6910555555555555\n",
      "18200 machine machines elephant elephants elephants 0.5408956606179126 actual: elephants 0.6918681318681319\n",
      "18400 onion onions child children children 0.5061565602422232 actual: children 0.6927717391304348\n",
      "18600 road roads pig pigs pigs 0.45635719960984766 actual: pigs 0.693763440860215\n",
      "18800 estimate estimates say says know 0.5408191099736609 actual: says 0.6931914893617022\n",
      "19000 play plays shuffle shuffles composes 0.32336827837727344 actual: shuffles 0.6928421052631579\n",
      "19200 shuffle shuffles speak speaks speaks 0.4804177180933778 actual: speaks 0.6917708333333333\n",
      "19400 think thinks vanish vanishes vanishes 0.5723545978838336 actual: vanishes 0.6911340206185567\n",
      "Final score: 0.690083913221449 13487 19544\n"
     ]
    }
   ],
   "source": [
    "def cosmul_sim(w, a, b, c, to_do, eps = 0.01):\n",
    "    \"\"\" 3COSMUL similarity \"\"\"\n",
    "    if to_do:\n",
    "        print(cos(w, c), cos(w, b), cos(w, a))\n",
    "    c1, c2, c3 = cos(w, c), cos(w, b), cos(w, a)\n",
    "    if to_do:\n",
    "        print(c1, c2, c3, (c1 * c2)/(c3 + eps))\n",
    "    if c3 < 0:\n",
    "        eps = -0.01\n",
    "    return c1 * c2/(c3 + eps)\n",
    "\n",
    "def cosine_sim(v, w, eps = 0.001, eps2 = 0.000001):\n",
    "    \"\"\"cosine similarity with numerical overflow protection or 3COSADD similarity\"\"\"\n",
    "    return np.dot(w, v)/((np.linalg.norm(w) + eps2) * (np.linalg.norm(v) + eps))\n",
    "\n",
    "\n",
    "def find_simi(lst, a, b, c, vocab, emb):\n",
    "    \"\"\"find argmax using 3COSADD method\"\"\"\n",
    "    v1 = b - a + c\n",
    "    amax = 0.\n",
    "    result = \"\"\n",
    "    for w2 in vocab:\n",
    "        if w2 not in lst:\n",
    "            sim = cosine_sim(emb[w2], v1)\n",
    "            if sim > amax:\n",
    "                result = w2\n",
    "                amax = sim\n",
    "    return result, amax\n",
    "\n",
    "\n",
    "def calculate_acc_for_analogies(anthologies, emb_gn, vocab_gn):\n",
    "    \"\"\" check accuracy of anthologies detection method using 3COSADD \"\"\"\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    a, b, c = \"\", \"\", \"\"\n",
    "    emb1, emb2, emb3 = [0], [0], [0]\n",
    "    for tup in anthologies:\n",
    "        # saving vectors to speed up computation\n",
    "        e1 = emb_gn[tup[0]] if a != tup[0] else emb1\n",
    "        e2 = emb_gn[tup[1]] if b != tup[1] else emb2\n",
    "        e3 = emb_gn[tup[2]] if c != tup[2] else emb3\n",
    "        # trying to find similar word as argmax(3COSADD(e2-e1+e3, E(w))) for all words w in vocab except tup[:3]\n",
    "        word, sim = find_simi(tup[:3], e1, e2, e3, vocab_gn, emb_gn)\n",
    "        if word == tup[3]:\n",
    "            corrects +=1\n",
    "        total +=1\n",
    "        emb1, emb2, emb3 = e1, e2, e3\n",
    "        a, b, c = tup[0], tup[1], tup[2]\n",
    "        if total % 200 == 0:\n",
    "            print(total, *tup, word, sim, \"actual:\", tup[3], corrects/total)\n",
    "    return corrects, total\n",
    "\n",
    "\n",
    "corrects, total = calculate_acc_for_analogies(anthologies, emb_gp_gn, vocab_gp_gn)\n",
    "print(f\"Final score: {corrects/total} {corrects} {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects, total = 13487, 19544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc_for_sem_analogies(anthologies, emb_gn, vocab_gn):\n",
    "    \"\"\" check accuracy of sem anthologies\n",
    "        initial accuracy was taken from row '8800 ...' of previous cell\n",
    "    \"\"\"\n",
    "    previous_res = \"8800 stepbrother stepsister policeman policewoman boyfriend 0.6182800965333808 actual: policewoman 0.7822727272727272\"\n",
    "    print(previous_res)\n",
    "    total = 8800\n",
    "    corrects = int(0.7822727272727272 * total)\n",
    "    total = 0\n",
    "    corrects = 0\n",
    "    a, b, c = \"\", \"\", \"\"\n",
    "    emb1, emb2, emb3 = [0], [0], [0]\n",
    "    for tup in anthologies[8800:8867]:\n",
    "        # saving vectors to speed up computation\n",
    "        e1 = emb_gn[tup[0]] if a != tup[0] else emb1\n",
    "        e2 = emb_gn[tup[1]] if b != tup[1] else emb2\n",
    "        e3 = emb_gn[tup[2]] if c != tup[2] else emb3\n",
    "        # trying to find similar word as argmax(3COSADD(e2-e1+e3, E(w))) for all words w in vocab except tup[:3]\n",
    "        word, sim = find_simi(tup[:3], e1, e2, e3, vocab_gn, emb_gn)\n",
    "        if word == tup[3]:\n",
    "            corrects +=1\n",
    "        total +=1\n",
    "        emb1, emb2, emb3 = e1, e2, e3\n",
    "        a, b, c = tup[0], tup[1], tup[2]\n",
    "        if total % 200 == 0:\n",
    "            print(total, *tup, word, sim, \"actual:\", tup[3], corrects/total)\n",
    "    print(total, *tup, word, sim, \"actual:\", tup[3], corrects/total)\n",
    "    return corrects , total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP-GN-GLOVE check\n",
      "200 havana cuba islamabad pakistan pakistan 0.6373196279240257 actual: pakistan 0.96\n",
      "400 paris france tokyo japan japan 0.6296925698790207 actual: japan 0.965\n",
      "600 algiers algeria belgrade serbia serbia 0.708826016842488 actual: serbia 0.97\n",
      "800 ashgabat turkmenistan cairo egypt egypt 0.595151121535518 actual: egypt 0.9675\n",
      "1000 baku azerbaijan dublin ireland ireland 0.5962528090608104 actual: ireland 0.972\n",
      "1200 beirut lebanon jakarta indonesia indonesia 0.6490071423248388 actual: indonesia 0.9725\n",
      "1400 bishkek kyrgyzstan lima peru peru 0.5495437757975783 actual: peru 0.9707142857142858\n",
      "1600 cairo egypt caracas venezuela venezuela 0.7132207770556203 actual: venezuela 0.969375\n",
      "1800 copenhagen denmark funafuti tuvalu tuvalu 0.46459788067411767 actual: tuvalu 0.9688888888888889\n",
      "2000 dublin ireland kampala uganda uganda 0.6038106880559133 actual: uganda 0.9705\n",
      "2200 hanoi vietnam ljubljana slovenia slovenia 0.5541343648369021 actual: slovenia 0.9686363636363636\n",
      "2400 jakarta indonesia mogadishu somalia somalia 0.6780990658261742 actual: somalia 0.9679166666666666\n",
      "2600 kiev ukraine nuuk greenland iceland 0.40000130409850637 actual: greenland 0.9661538461538461\n",
      "2800 lima peru roseau dominica dominica 0.44465911647075673 actual: dominica 0.9635714285714285\n",
      "3000 lusaka zambia tegucigalpa honduras honduras 0.6441629505448491 actual: honduras 0.9626666666666667\n",
      "3200 minsk belarus montevideo uruguay uruguay 0.7333963502925189 actual: uruguay 0.9634375\n",
      "3400 muscat oman ottawa canada toronto 0.431938070610503 actual: canada 0.9623529411764706\n",
      "3600 nouakchott mauritania skopje macedonia macedonia 0.6640288426759562 actual: macedonia 0.9602777777777778\n",
      "3800 paris france thimphu bhutan bhutan 0.47523856173428114 actual: bhutan 0.96\n",
      "4000 rome italy warsaw poland poland 0.6169038776631433 actual: poland 0.9605\n",
      "4200 stockholm sweden apia samoa samoa 0.524343285592901 actual: samoa 0.9576190476190476\n",
      "4400 tbilisi georgia beijing china china 0.5279072138828167 actual: china 0.9586363636363636\n",
      "4600 tokyo japan budapest hungary hungary 0.6681144503531204 actual: hungary 0.9595652173913043\n",
      "4800 vientiane laos yerevan armenia armenia 0.5765981820224497 actual: armenia 0.96125\n",
      "5000 zagreb croatia asmara eritrea eritrea 0.5868576743703237 actual: eritrea 0.9628\n",
      "5200 bulgaria lev angola kwanza angolan 0.406322030776092 actual: kwanza 0.9328846153846154\n",
      "5400 india rupee cambodia riel shilling 0.44978944860533104 actual: riel 0.9012962962962963\n",
      "5600 malaysia ringgit europe euro saceur 0.29430337232778697 actual: euro 0.8714285714285714\n",
      "5800 thailand baht korea won rmb 0.48968230268170404 actual: won 0.843103448275862\n",
      "6000 philadelphia pennsylvania bakersfield california fresno 0.38431282274472633 actual: california 0.8296666666666667\n",
      "6200 detroit michigan louisville kentucky kentucky 0.6364325682579873 actual: kentucky 0.8287096774193549\n",
      "6400 baltimore maryland oakland california california 0.4857728484338129 actual: california 0.82390625\n",
      "6600 tucson arizona anchorage alaska alaska 0.5947009981468523 actual: alaska 0.8183333333333334\n",
      "6800 miami florida anaheim california california 0.41869847994193476 actual: california 0.8101470588235294\n",
      "7000 wichita kansas modesto california fresno 0.40932464428248655 actual: california 0.804\n",
      "7200 pittsburgh pennsylvania fremont california wyoming 0.39426859058359603 actual: california 0.8005555555555556\n",
      "7400 toledo ohio indianapolis indiana indiana 0.48377784197598245 actual: indiana 0.7972972972972973\n",
      "7600 madison wisconsin chicago illinois milwaukee 0.5523532710202668 actual: illinois 0.7932894736842105\n",
      "7800 scottsdale arizona shreveport louisiana louisiana 0.6085569596708524 actual: louisiana 0.7897435897435897\n",
      "8000 shreveport louisiana tacoma washington washington 0.41432606396247135 actual: washington 0.78375\n",
      "8200 amarillo texas portland oregon oregon 0.5932511820561335 actual: oregon 0.7829268292682927\n",
      "8400 brother sister prince princess princess 0.7709663158315151 actual: princess 0.7814285714285715\n",
      "8600 his her father mother mother 0.8050790041483592 actual: mother 0.7827906976744186\n",
      "8800 stepbrother stepsister policeman policewoman boyfriend 0.6182800965333808 actual: policewoman 0.7822727272727272\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e375e77eb3c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msem_corrects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_acc_for_sem_analogies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manthologies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_gp_gn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_gp_gn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GP-GN-GLOVE accuracy of sem anthologies: {sem_corrects/sem_total} {sem_corrects} {sem_total}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msyn_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcorrects\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msem_corrects\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msem_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GP-GN-GLOVE accuracy of syn anthologies: {syn_acc} correct answers: {corrects - sem_corrects}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GP-GN-GLOVE overal accuracy for anthologies: {corrects/ total} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-850f0c192e04>\u001b[0m in \u001b[0;36mcalculate_acc_for_sem_analogies\u001b[0;34m(anthologies, emb_gn, vocab_gn)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0me3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_gn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0memb3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# trying to find similar word as argmax(3COSADD(e2-e1+e3, E(w))) for all words w in vocab except tup[:3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_simi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_gn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_gn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mcorrects\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-67f402910ef9>\u001b[0m in \u001b[0;36mfind_simi\u001b[0;34m(lst, a, b, c, vocab, emb)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mamax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-67f402910ef9>\u001b[0m in \u001b[0;36mcosine_sim\u001b[0;34m(v, w, eps, eps2)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m\"\"\"cosine similarity with numerical overflow protection or 3COSADD similarity\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"GP-GN-GLOVE check\")\n",
    "sem_corrects, sem_total = calculate_acc_for_sem_analogies(anthologies, emb_gp_gn, vocab_gp_gn)\n",
    "print(f\"GP-GN-GLOVE accuracy of sem anthologies: {sem_corrects/sem_total} {sem_corrects} {sem_total}\")\n",
    "syn_acc = (corrects - sem_corrects) / (total - sem_total)\n",
    "print(f\"GP-GN-GLOVE accuracy of syn anthologies: {syn_acc} correct answers: {corrects - sem_corrects}\")\n",
    "print(f\"GP-GN-GLOVE overal accuracy for anthologies: {corrects/ total} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "debiassing_repli.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
